<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description" content="Exploration of attention maps in Stable Diffusion">
    <meta property="og:title" content="Deep Learning 2023 course project" />
    <meta property="og:description" content="Exploration of attention maps in Stable Diffusion" />
    <meta property="og:url" content="https://chrisoffner.github.io/dl23_course_project/" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <!-- <meta property="og:image" content="static/image/your_banner_image.png" /> -->
    <meta property="og:image:height" content="630" />


    <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image"> -->
    <!-- Keywords for your paper to be indexed by-->
    <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
    <meta name="viewport" content="width=device-width, initial-scale=1"> -->


    <title>Deep Learning course</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Deep Learning 2023 course project</h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                                <a href="mailto:coffner@student.ethz.ch" target="_blank">Chris
                                    Offner</a>,</span>
                            <span class="author-block">
                                <a href="mailto:cbraeuer@student.ethz.ch" target="_blank">Claire
                                    Bräuer</a>,</span>
                            <span class="author-block">
                                <a href="mailto:keviqu@student.ethz.ch" target="_blank">Kevin Qu</a>,
                            </span>
                            <span class="author-block">
                                <a href="mailto:apolinarska@arch.ethz.ch" target="_blank">Aleksandra Anna Apolinarska</a>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block">ETH Zurich</span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Self-attention maps animated-->
    <section class="hero teaser">
        <div class="container is-max-desktop">
            <h2 class="title is-3">Self-attention maps animated</h2>
            <div class="hero-body">
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                    <source src="static/videos/bear_self_attn.mp4" type="video/mp4">
                </video>
                <h2 class="subtitle has-text-centered">
                    We visualise the self-attention maps extracted from Stable Diffusion. Each channel corresponds to
                    the attention map of one latent pixel and encodes the probability of the latent pixel attending to
                    (or being attended to by) the other latent pixels. We display each such channel as a frame in this
                    video.
                </h2>
            </div>
        </div>
    </section>
    <!-- End teaser video -->

    <!-- Self-attention maps animated-->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <h2 class="title is-3">Four resolutions, two interpretations each</h2>
            <div class="hero-body">
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                    <source src="static/videos/self_attn_all_res.mp4" type="video/mp4">
                </video>
                <h2 class="subtitle has-text-centered">
                    Self-attention maps are computed at 8x8, 16x16, 32x32, and 64x64 resolution in the U-Net of Stable Diffusion. Each map is an <code>(r^2, r^2)</code> tensor for <code>r = 8, 16, 32, 64</code>. The top row reshapes it to <code>(r^2, r, r)</code>, the bottom row to <code>(r, r, r^2)</code>. Each of the <code>r^2</code> channels corresponds to a pixel.
                </h2>
            </div>
        </div>
    </section>
    <!-- End teaser video -->


    <!-- Teaser video-->
    <section class="hero teaser">
        <div class="container is-max-desktop">
            <h2 class="title is-3">Glitches in GPU-computed attention maps</h2>
            <div class="hero-body">
                <video poster="" id="tree" autoplay controls muted loop height="100%">
                    <!-- Your video here -->
                    <source src="static/videos/diffusion_CPU_vs_GPU.m4v" type="video/mp4">
                </video>
                <h2 class="subtitle has-text-centered">
                    The video on the left shows the progression of cross-attention maps computed via the CPU. The right
                    side shows
                    the same cross-attention maps computed via the GPU. Both use the Keras implementation of Stable
                    Diffusion on an M3 Max chip. After noticing these artifacts, we decided to perform all subsequent
                    experiments on the CPU, incurring a significant performance penalty.
                </h2>
            </div>
        </div>
    </section>
    <!-- End teaser video -->


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a
                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                            You are free to borrow the of this website, we just ask that you link back to this page in
                            the footer. <br> This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>